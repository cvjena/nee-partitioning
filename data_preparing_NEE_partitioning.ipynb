{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/trifunov/anaconda3/envs/dmm/lib/python2.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "import random\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from skimage.transform import rotate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.linalg import sqrtm\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "import datetime\n",
    "import sunrise\n",
    "import pytz\n",
    "from tzwhere import tzwhere\n",
    "tzwhere = tzwhere.tzwhere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"yourdatapath\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(variable):\n",
    "        normalized_var = (variable - np.mean(variable)) / np.std(variable)\n",
    "        return normalized_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sunrise_sunset(lat, lon, start_datetime):\n",
    "        \"\"\"\n",
    "        A function that determines the sunrise and the sunset times based on the geographical coordinates of the FLUXNET site\n",
    "        \n",
    "        Input:\n",
    "        latitude - integer value of the latitude of the given FLUXNET site \n",
    "        longitude - integer value of the longitude of the given FLUXNET site\n",
    "        start_datetime - timestamp variable of the FLUXNET site containing integers of the format YYYYMMDDHHMinMin\n",
    "        (e.g. 202101291857)\n",
    "\n",
    "        Output:\n",
    "        sunrise_time - integer value of the time of the day when the sun rises on a given FLUXNET site of the form HMinMin (e.g. 531)\n",
    "        sunset_time - integer value of the time of the day when the sun sets on a given FLUXNET site of the form HHMinMin (e.g. 2104)\n",
    "        \"\"\"\n",
    "        timezone_str = tzwhere.tzNameAt(lat, lon)\n",
    "        timezone = pytz.timezone(timezone_str)\n",
    "        M = len(start_datetime)\n",
    "        sunrise_time = np.zeros(M)\n",
    "        sunset_time = np.zeros(M)\n",
    "        days = [None] * M\n",
    "\n",
    "        for i in range(M):\n",
    "            s = sunrise.sun(lat=lat,long=lon)\n",
    "            year = int(start_datetime[i]) // 100000000\n",
    "            month = (int(start_datetime[i]) % 100000000) // 1000000\n",
    "            day = (int(start_datetime[i]) % 1000000) // 10000\n",
    "            day_input = datetime.datetime(year, month, day)\n",
    "            srise = s.sunrise(when=day_input)\n",
    "            sset = s.sunset(when=day_input)\n",
    "            srise = pytz.utc.localize(day_input.replace(hour=srise.hour, minute=srise.minute))\n",
    "            sset = pytz.utc.localize(day_input.replace(hour=sset.hour, minute=sset.minute))\n",
    "            sunrise_time[i] = int(srise.astimezone(timezone).strftime('%H%M'))\n",
    "            sunset_time[i] = int(sset.astimezone(timezone).strftime('%H%M'))\n",
    "            days[i] = day_input\n",
    "        return sunrise_time, sunset_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_night(variable, timestamp, sunrise_time, sunset_time):\n",
    "    \"\"\"\n",
    "    A function that takes a time series variable as input and outputs its daytime and nighttime values as separate variables.\n",
    "\n",
    "    Input:\n",
    "    variable - time series variable starting at midnight\n",
    "    timestamp - array of integers denoting the date and time in the format YYYYMMDDHHMinMin\n",
    "    sunrise_time - integer hour of day when the daylight starts (6:30 --> 630)\n",
    "    sunset_time - integer hour of day when the daylight ends (21:00 --> 2130)\n",
    "\n",
    "    Output:\n",
    "    variable_day - daytime values of the input variable\n",
    "    variable_night - nighttime values of the input variable\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(variable)\n",
    "    # m = n // 24\n",
    "    variable_day = np.empty(n)\n",
    "    variable_day[:] = np.NaN\n",
    "    variable_night = np.empty(n)\n",
    "    variable_night[:] = np.NaN\n",
    "    time_of_day = np.array(timestamp % 10000)\n",
    "    for i in range(n):\n",
    "        if (time_of_day[i] >= sunset_time[i] + 100) or (time_of_day[i] < sunrise_time[i] - 100): #100 denotes 1 hour, making sure there is not sunlight for photosynthesis\n",
    "            variable_night[i] = variable[i]\n",
    "        else:\n",
    "            variable_day[i] = variable[i]\n",
    "\n",
    "    return variable_night, variable_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eco_vars_csv(site_name):\n",
    "    \"\"\"\n",
    "    A function for loading data from a FLUXNET site in csv format.\n",
    "\n",
    "    Input:\n",
    "    site_name - string, name of the data file\n",
    "    Output:\n",
    "    Ecological variables of interest from that site\n",
    "    \"\"\"\n",
    "    \n",
    "    real_eco_data_csv = pd.read_csv(path+site_name, skip_blank_lines=False)\n",
    "    \n",
    "    #load desired FLUXNET variables\n",
    "    radiation = real_eco_data_csv['SW_IN_F_MDS']\n",
    "    temperature = real_eco_data_csv['TA_F_MDS']\n",
    "    respiration = real_eco_data_csv['RECO_NT_VUT_USTAR50']\n",
    "    GPP = real_eco_data_csv['GPP_NT_VUT_USTAR50']\n",
    "    NEE = real_eco_data_csv['NEE_VUT_USTAR50']\n",
    "    precipitation = real_eco_data_csv['P_F']\n",
    "    VPD = real_eco_data_csv['VPD_F_MDS']\n",
    "    start_datetime = real_eco_data_csv['TIMESTAMP_START']\n",
    "    SWC = real_eco_data_csv['SWC_F_MDS_1']\n",
    "    SWC_T = real_eco_data_csv['TS_F_MDS_1']\n",
    "    WS = real_eco_data_csv['WS_F']\n",
    "    WD = real_eco_data_csv['WD']\n",
    "\n",
    "    # load site coordinates from .csv file\n",
    "    coordinates = pd.read_csv(\"fluxnet-site-coordinates.csv\", sep='\\t', header = None)\n",
    "    len_sites = coordinates.iloc[:,0].shape[0]\n",
    "    site_name_short = site_name.split('/')[-1]\n",
    "    for i in range(len_sites):\n",
    "        if coordinates.iloc[i,0] == site_name_short[4:10]:\n",
    "            lat = coordinates.iloc[i,2]\n",
    "            lon = coordinates.iloc[i,3]\n",
    "    return radiation, temperature, respiration, GPP, NEE, precipitation, VPD, float(lat), float(lon), start_datetime, SWC, SWC_T, WS, WD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxnet_sites_HH = [f for f in os.listdir(\"path_of_your_fluxnet_sites\")]\n",
    "for site in fluxnet_sites_HH:\n",
    "    radiation, temperature, respiration, GPP, NEE, precipitation, VPD, latitude, longitude, start_datetime, SWC, T_soil, WS, WD = load_eco_vars_csv(\"FLUXNETsites-from-ANN-partitioning-paper/\" + site)\n",
    "\n",
    "    radiation = radiation.to_numpy()\n",
    "    temperature = temperature.to_numpy()\n",
    "    respiration = respiration.to_numpy()\n",
    "    GPP = GPP.to_numpy()\n",
    "    NEE = NEE.to_numpy()\n",
    "    precipitation = precipitation.to_numpy()\n",
    "    VPD = VPD.to_numpy()\n",
    "    SWC = SWC.to_numpy()\n",
    "    T_soil = T_soil.to_numpy()\n",
    "    WS = WS.to_numpy()\n",
    "    WD = WD.to_numpy()\n",
    "    start_datetime = start_datetime.astype(float)\n",
    "\n",
    "    ts_length = len(radiation)\n",
    "\n",
    "    radiation_normalized = normalize(radiation)\n",
    "    temperature_normalized = normalize(temperature)\n",
    "    #GPP_normalized = normalize(GPP_noisy) #for synthetic data\n",
    "    GPP_normalized = normalize(GPP)\n",
    "    respiration_normalized = normalize(respiration)\n",
    "    precipitation_normalized = normalize(precipitation)\n",
    "    NEE_normalized = normalize(NEE)\n",
    "    VPD_normalized = normalize(VPD)\n",
    "    SWC_normalized = normalize(SWC)\n",
    "    T_soil_normalized = normalize(T_soil)\n",
    "    WS_normalized = normalize(WS)\n",
    "    WD_normalized = normalize(WD)\n",
    "\n",
    "    years = int(ts_length / (365 * 48)) #half-hourly data\n",
    "    T = 30*48\n",
    "    num_eco_vars = 14\n",
    "\n",
    "    def create_sliding_window_eco_dataset(list_months, measure, ts_length, R_g, T_air, GPP, R_eco, NEE, Pr, VPD, latitude, longitude, start_datetime, SWC, T_soil, WS, WD, num_vars, sample_length, shift, reps):\n",
    "        \"\"\"\n",
    "        Function creating a train, validation, test split of the input ecological variables using sliding windows to augment the data\n",
    "        ***************\n",
    "        list_months - list of integers from 1 to 12 in an increasing order denoting months of the year to be included in the dataset\n",
    "        measure - integer denoting if one year of data is measured daily (1), hourly (24) or half-hourly (48)\n",
    "        ts_length - integer denoting the length of the FLUXNET site used\n",
    "        R_g - time series of global radiation\n",
    "        T_air - time series of air temperature\n",
    "        GPP - time series of global primary production\n",
    "        R_eco - time series of ecosystem respiration\n",
    "        NEE - time series of net ecosystem exchange\n",
    "        Pr - time series of precipitation\n",
    "        VPD - time series of vapor pressure deficit\n",
    "        latitude - float of latitude of the fluxnet site the data is coming from\n",
    "        longitude - float longitude of the fluxnet site the data is coming from\n",
    "        start_datetime - timestamp_start variable of the fluxnet site noting integer of the format YYYYMMDDHHMinMin (year, month, day, hour, minute)\n",
    "        SWC - time series of soil water content\n",
    "        T_soil - time series of soil temperature\n",
    "        WS - time series of wind speed\n",
    "        WD - time series of wind direction\n",
    "        ANN_Reco - time series of Reco estimated by the ANN partitioning method (NN_part in the paper)\n",
    "        num_vars - integer denoting the number of ecological variables and their components (such as seasonal cycle) in the new dataset\n",
    "        sample_length - integer denoting the length of the sample in days\n",
    "        shift - integer denoting the number of days two sliding windows are apart from each other\n",
    "        reps - integer denoting the number of replications of the data\n",
    "\n",
    "        \"\"\"\n",
    "        M = len(list_months)\n",
    "        J = 30 // shift\n",
    "        T = sample_length * measure\n",
    "        years = int(ts_length / (365 * measure))\n",
    "        data_train = np.zeros([M*(years-2)*J*reps, T, num_vars])\n",
    "        data_valid = np.zeros([M * J * reps, T, num_vars])\n",
    "        sunrise_time, sunset_time = get_sunrise_sunset(latitude, longitude, start_datetime)\n",
    "\n",
    "        for rep in range(reps):\n",
    "            noise_1 = np.random.normal(0, 0.5, ts_length)\n",
    "            np.random.seed(1 + rep * 100)\n",
    "            noise_2 = np.random.normal(0, 0.5, ts_length)\n",
    "            np.random.seed(10 + rep *200)\n",
    "            noise_3 = np.random.normal(0, 0.5, ts_length)\n",
    "            np.random.seed(100 + rep *300)\n",
    "            noise_4 = np.random.normal(0, 0.5, ts_length)\n",
    "            for i in range(M):\n",
    "                for year in range(years):\n",
    "                    for j in range(J):\n",
    "                        if year < (years - 2):\n",
    "                            data_train[(((years-2) * i + year) * J + j) * reps + rep, :, 0] = R_g[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_train[(((years-2) * i + year) * J + j) * reps + rep, :, 1] = T_air[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_train[(((years-2) * i + year) * J + j) * reps + rep, :, 2], _ = day_night(NEE[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure], start_datetime[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure], sunrise_time[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure], sunset_time[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure])\n",
    "                            data_train[(((years-2) * i + year) * J + j) * reps + rep, :, 3], _ = day_night(GPP[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure], start_datetime[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure], sunrise_time[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure], sunset_time[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure])\n",
    "                            data_train[(((years-2) * i + year) * J + j) * reps + rep, :, 4] = GPP[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_train[(((years-2) * i + year) * J + j) * reps + rep, :, 5] = NEE[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_train[(((years-2) * i + year) * J + j) * reps + rep, :, 6] = Pr[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_train[(((years-2) * i + year) * J + j) * reps + rep, :, 7] = VPD[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_train[(((years-2) * i + year) * J + j) * reps + rep, :, 8] = R_eco[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "\n",
    "                            data_train[(((years-2) * i + year) * J + j) * reps + rep, :, 9] = start_datetime[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "\n",
    "                            data_train[(((years-2) * i + year) * J + j) * reps + rep, :, 10] = SWC[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_train[(((years-2) * i + year) * J + j) * reps + rep, :, 11] = T_soil[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_train[(((years-2) * i + year) * J + j) * reps + rep, :, 12] = WS[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_train[(((years-2) * i + year) * J + j) * reps + rep, :, 13] = WD[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                        # when using an unseen year for the test    \n",
    "                        elif year == years-2:\n",
    "                            data_valid[(J * i + j) * reps + rep, :, 0]= R_g[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_valid[(J * i + j) * reps + rep, :, 1] = T_air[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_valid[(J * i + j) * reps + rep, :, 2], _ = day_night(NEE[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure], start_datetime, sunrise_time, sunset_time)\n",
    "                            data_valid[(J * i + j) * reps + rep, :, 3], _ = day_night(GPP[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure], start_datetime, sunrise_time, sunset_time)\n",
    "                            data_valid[(J * i + j) * reps + rep, :, 4] = GPP[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_valid[(J * i + j) * reps + rep, :, 5] = NEE[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_valid[(J * i + j) * reps + rep, :, 6] = Pr[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_valid[(J * i + j) * reps + rep, :, 7] = VPD[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_valid[(J * i + j) * reps + rep, :, 8] = R_eco[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "\n",
    "                            data_valid[(J * i + j) * reps + rep, :, 9] = start_datetime[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "\n",
    "                            data_valid[(J * i + j) * reps + rep, :, 10] = SWC[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_valid[(J * i + j) * reps + rep, :, 11] = T_soil[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_valid[(J * i + j) * reps + rep, :, 12] = WS[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "                            data_valid[(J * i + j) * reps + rep, :, 13] = WD[(year * 365 + 30 * list_months[i] + shift * j) * measure:(year * 365 + 30 * list_months[i] + sample_length + shift * j) * measure]\n",
    "\n",
    "\n",
    "    return data_train, data_valid\n",
    "\n",
    "    #picking the summer months June, July, August, September\n",
    "    data_train, data_valid = create_sliding_window_eco_dataset([6, 7, 8, 9], 48, ts_length, radiation, temperature, GPP, respiration, NEE, precipitation, VPD, latitude, longitude, start_datetime, SWC, T_soil, WS, WD, num_eco_vars, 7, 2, 1)\n",
    "\n",
    "    site_name = site.split('.')[0]\n",
    "    np.savez(path + \"prepared_FLUXNET_sites-numpy/\" + site_name + \"_June-to-September\", data_train, data_valid, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dmm]",
   "language": "python",
   "name": "conda-env-dmm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
